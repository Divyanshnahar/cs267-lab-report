{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Divyanshnahar/cs267-lab-report/blob/main/LAB-2/plagiarism_Astar.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import heapq\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# -----------------------------\n",
        "# TEXT PREPROCESSING\n",
        "# -----------------------------\n",
        "def preprocess(text):\n",
        "    \"\"\"Convert text to lowercase, remove punctuation, and split into sentences.\"\"\"\n",
        "    sentences = sent_tokenize(text.lower())\n",
        "    sentences = [re.sub(r'[^\\w\\s]', '', s).strip() for s in sentences if s.strip()]\n",
        "    return sentences\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# COST FUNCTION\n",
        "# -----------------------------\n",
        "def cost_function(a, b):\n",
        "    \"\"\"Sentence matching cost with sharper penalty for dissimilar text.\"\"\"\n",
        "    if a == b:\n",
        "        return 0.0\n",
        "\n",
        "    # Token-based difference instead of per-character\n",
        "    a_tokens = a.split()\n",
        "    b_tokens = b.split()\n",
        "    overlap = len(set(a_tokens) & set(b_tokens))\n",
        "    total = max(len(a_tokens), len(b_tokens), 1)\n",
        "\n",
        "    similarity = overlap / total\n",
        "    cost = (1 - similarity) * 10.0  # strong penalty for low overlap\n",
        "    return cost\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# A* SEARCH ALIGNMENT\n",
        "# -----------------------------\n",
        "def a_star_search(doc1_sents, doc2_sents):\n",
        "    \"\"\"Find minimal alignment cost between two sets of sentences.\"\"\"\n",
        "    n, m = len(doc1_sents), len(doc2_sents)\n",
        "    pq = [(0, 0, 0)]  # (cost, i, j)\n",
        "    visited = set()\n",
        "\n",
        "    while pq:\n",
        "        cost, i, j = heapq.heappop(pq)\n",
        "        if (i, j) in visited:\n",
        "            continue\n",
        "        visited.add((i, j))\n",
        "\n",
        "        if i == n and j == m:\n",
        "            return cost\n",
        "\n",
        "        if i < n and j < m:\n",
        "            heapq.heappush(pq, (cost + cost_function(doc1_sents[i], doc2_sents[j]), i + 1, j + 1))\n",
        "        if i < n:\n",
        "            heapq.heappush(pq, (cost + 8.0, i + 1, j))\n",
        "        if j < m:\n",
        "            heapq.heappush(pq, (cost + 8.0, i, j + 1))\n",
        "\n",
        "    return float(\"inf\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# PLAGIARISM DETECTION\n",
        "# -----------------------------\n",
        "def detect_plagiarism(doc1, doc2):\n",
        "    \"\"\"Detect plagiarism using alignment cost and similarity score.\"\"\"\n",
        "    doc1_sents = preprocess(doc1)\n",
        "    doc2_sents = preprocess(doc2)\n",
        "\n",
        "    alignment_cost = a_star_search(doc1_sents, doc2_sents)\n",
        "\n",
        "    total_len = max(len(\" \".join(doc1_sents)), len(\" \".join(doc2_sents)), 1)\n",
        "    similarity = max(0, 1 - alignment_cost / (total_len / 3.5))  # stronger normalization\n",
        "\n",
        "    if similarity >= 0.9:\n",
        "        label = \"⚠️ Potential plagiarism detected\"\n",
        "    elif similarity >= 0.6:\n",
        "        label = \"⚠️ Partial similarity detected\"\n",
        "    else:\n",
        "        label = \"✅ No plagiarism detected\"\n",
        "\n",
        "    print(f\"{label} (Alignment Cost: {alignment_cost:.2f}, Similarity: {similarity*100:.2f}%)\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# TEST CASES\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n--- Test Case 1: Identical Documents ---\")\n",
        "    detect_plagiarism(\n",
        "        \"Artificial Intelligence is the study of intelligent agents.\",\n",
        "        \"Artificial Intelligence is the study of intelligent agents.\"\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- Test Case 2: Slightly Modified Documents ---\")\n",
        "    detect_plagiarism(\n",
        "        \"Artificial Intelligence is the study of intelligent agents.\",\n",
        "        \"AI is the study of smart agents.\"\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- Test Case 3: Totally Different Documents ---\")\n",
        "    detect_plagiarism(\n",
        "        \"The sun rises in the east and sets in the west.\",\n",
        "        \"Machine learning algorithms improve through experience.\"\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- Test Case 4: Partially Overlapped Documents ---\")\n",
        "    detect_plagiarism(\n",
        "        \"Artificial Intelligence techniques are applied in robotics and healthcare.\",\n",
        "        \"Robotics and healthcare use Artificial Intelligence for automation.\"\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
